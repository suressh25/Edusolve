# ============================================================================
# EDUSOLVE - MULTI-PROVIDER API CONFIGURATION
# ============================================================================

# === PRIMARY PROVIDERS (Minimum Required) ===

# Groq - Fast inference, primary text generation (REQUIRED)
# Get free key: https://console.groq.com/keys
# Limits: 1,000 req/day for Llama 3.3 70B, 14,400 req/day for Llama 3.1 8B
GROQ_API_KEY=your_groq_api_key_here

# Google Gemini - Vision/OCR for image processing (REQUIRED for scanned PDFs/images)
# Get free key: https://aistudio.google.com/app/apikey
# Limits: 15 RPM, 50 RPD for vision models
GEMINI_API_KEY=your_gemini_api_key_here

# === SECONDARY PROVIDERS (Highly Recommended for Production) ===

# Cerebras - Ultra-fast inference, secondary text generation (RECOMMENDED)
# Get free key: https://cloud.cerebras.ai/
# Limits: 30 RPM, 14,400 RPD, 1M tokens/day per model
CEREBRAS_API_KEY=your_cerebras_api_key_here

# Mistral La Plateforme - High-volume fallback (RECOMMENDED)
# Get free key: https://console.mistral.ai/
# Limits: 60 RPM, 500k TPM, 1B tokens/month (requires phone verification)
MISTRAL_API_KEY=your_mistral_api_key_here

# === OPTIONAL PROVIDERS (Additional Fallbacks) ===

# OpenRouter - Multi-model access, emergency fallback
# Get free key: https://openrouter.ai/keys
# Limits: 20 RPM, 50 RPD (can upgrade to 1000 RPD with $10 lifetime topup)
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Cohere - RAG embeddings and advanced generation
# Get free key: https://dashboard.cohere.com/api-keys
# Limits: 20 RPM, 1,000 requests/month
COHERE_API_KEY=your_cohere_api_key_here

# Cloudflare Workers AI - Edge processing (optional)
# Get free key: https://dash.cloudflare.com/
# Limits: 10,000 neurons/day
CLOUDFLARE_API_KEY=your_cloudflare_api_key_here
CLOUDFLARE_ACCOUNT_ID=your_cloudflare_account_id_here

# === LEGACY PROVIDERS (Deprecated - kept for backward compatibility) ===

# HuggingFace - Limited compatibility, not recommended for new deployments
# Use Cerebras or Mistral instead for better reliability
HUGGINGFACE_API_KEY=your_huggingface_api_key_here

# ============================================================================
# APPLICATION CONFIGURATION
# ============================================================================

# === RAG Configuration ===
# Chunk size for document splitting (characters)
CHUNK_SIZE=1000

# Overlap between chunks to maintain context
CHUNK_OVERLAP=200

# Number of top relevant chunks to retrieve for context
TOP_K_RESULTS=5

# Local embedding model for RAG (HuggingFace model name)
HF_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# === File Upload Settings ===
# Maximum file size in megabytes
MAX_FILE_SIZE_MB=10

# Allowed file extensions (comma-separated, no spaces)
ALLOWED_EXTENSIONS=pdf,docx,txt,jpg,png,jpeg

# ============================================================================
# SETUP INSTRUCTIONS
# ============================================================================
#
# MINIMUM SETUP (Start here):
# 1. Get GROQ_API_KEY from https://console.groq.com/keys
# 2. Get GEMINI_API_KEY from https://aistudio.google.com/app/apikey
# 3. Remove "your_" prefix and add your actual keys
#
# RECOMMENDED SETUP (For production):
# 1. Complete minimum setup above
# 2. Get CEREBRAS_API_KEY from https://cloud.cerebras.ai/
# 3. Get MISTRAL_API_KEY from https://console.mistral.ai/
#
# FULL SETUP (Maximum reliability):
# 1. Complete recommended setup above
# 2. Get OPENROUTER_API_KEY from https://openrouter.ai/keys
# 3. Get COHERE_API_KEY from https://dashboard.cohere.com/api-keys
#
# ============================================================================
